heat_template_version: queens

description: >
  FirstBoot Script that applies some configuration through CloudInit

parameters:
  NodeRootPassword:
    description: Root password for the nodes
    hidden: true
    type: string
  InitNTPServer:
    description: Initial NTP Server for HW Clock sync
    type: string

resources:
  userdata:
    type: OS::Heat::MultipartMime
    properties:
      parts:
      - config: {get_resource: root_config}
      - config: {get_resource: disk_wipe}
      - config: {get_resource: clocksync}
      - config: {get_resource: patch_rhbz1624441}

  root_config:
    type: OS::Heat::CloudConfig
    properties:
      cloud_config:
        ssh_pwauth: true
        disable_root: false
        chpasswd:
          list:
            str_replace:
              template: "root:PASSWORD"
              params:
                PASSWORD: {get_param: NodeRootPassword}
          expire: False

  disk_wipe:
    type: OS::Heat::SoftwareConfig
    properties:
      config: |
        #!/bin/bash
        echo "Number of disks detected: $(lsblk -no NAME,TYPE,MOUNTPOINT | grep "disk" | awk '{print $1}' | wc -l)"
        for DEVICE in `lsblk -no NAME,TYPE,MOUNTPOINT | grep "disk" | awk '{print $1}'`
        do
          ROOTFOUND=0
          echo "Checking /dev/$DEVICE..."
          echo "Number of partitions on /dev/$DEVICE: $(expr $(lsblk -n /dev/$DEVICE | awk '{print $7}' | wc -l) - 1)"
          for MOUNTS in `lsblk -n /dev/$DEVICE | awk '{print $7}'`
          do
            if [ "$MOUNTS" = "/" ]
            then
              ROOTFOUND=1
            fi
          done
          if [ $ROOTFOUND = 0 ]
          then
            echo "Root not found in /dev/${DEVICE}"
            echo "Wiping disk /dev/${DEVICE}"
            sgdisk -Z /dev/${DEVICE}
            sgdisk -g /dev/${DEVICE}
          else
            echo "Root found in /dev/${DEVICE}"
          fi
        done

  clocksync:
    type: OS::Heat::SoftwareConfig
    properties:
      config:
        str_replace:
          template: |
            #!/bin/bash
            # Make sure the clock is synced due to https://bugzilla.redhat.com/show_bug.cgi?id=1578849
            sed -e "s/^SYNC_HWCLOCK=no$/SYNC_HWCLOCK=yes/g" -i /etc/sysconfig/ntpdate
            ntpdate -qud $INITNTPServer
            hwclock --systohc
          params:
            $INITNTPServer: {get_param: InitNTPServer}

  patch_rhbz1624441:
    type: OS::Heat::SoftwareConfig
    properties:
      config: |
        #!/bin/bash
        
        # https://bugzilla.redhat.com/show_bug.cgi?id=1624441
        # https://review.openstack.org/#/c/624349/
        # https://review.openstack.org/#/c/624352/
        
        echo "Patching corosync.pp in puppet-pacemaker and pacemaker.pp in puppet-tripleo due to rhbz#1624441 - OSP13z4-only fixed in OSP13z5"
        
        rpm -q puppet-pacemaker-0.7.2-0.20180423212255.el7ost.noarch && patch -d/ -p0 <<'EOF'
        --- /etc/puppet/modules/pacemaker/manifests/corosync.pp
        +++ /etc/puppet/modules/pacemaker/manifests/corosync.pp
        @@ -148,6 +148,7 @@
               password => pw_hash($::pacemaker::hacluster_pwd, 'SHA-512', fqdn_rand_string(10)),
               groups   => 'haclient',
               require  => Class['::pacemaker::install'],
        +      before   => Service['pcsd'],
               notify   => Exec['reauthenticate-across-all-nodes'],
             }
        
        @@ -157,17 +158,17 @@
               timeout     => $settle_timeout,
               tries       => $settle_tries,
               try_sleep   => $settle_try_sleep,
        +      require     => Service['pcsd'],
               tag         => 'pacemaker-auth',
             }
        
        -    Service['pcsd'] ->
             exec { 'auth-successful-across-all-nodes':
               command     => "${::pacemaker::pcs_bin} cluster auth ${cluster_members} -u hacluster -p ${::pacemaker::hacluster_pwd}",
               refreshonly => true,
               timeout     => $settle_timeout,
               tries       => $settle_tries,
               try_sleep   => $settle_try_sleep,
        -      require     => User['hacluster'],
        +      require     => [Service['pcsd'], User['hacluster']],
               unless      => "${::pacemaker::pcs_bin} cluster auth ${cluster_members} -u hacluster -p ${::pacemaker::hacluster_pwd} | grep 'Already authorized'",
               tag         => 'pacemaker-auth',
             }
        @@ -258,11 +259,7 @@
               mode    => '0640',
               content => $remote_authkey,
             }
        -    Exec <| title == 'auth-successful-across-all-nodes' |> -> File['etc-pacemaker-authkey']
        -    if $setup_cluster {
        -      Exec["Create Cluster ${cluster_name}"] -> File['etc-pacemaker-authkey']
        -      File['etc-pacemaker-authkey'] -> Exec["Start Cluster ${cluster_name}"]
        -    }
        +    File['etc-pacemaker-authkey'] -> Service['pcsd']
           }
        
           exec {'wait-for-settle':
        EOF
        
        rpm -q puppet-tripleo-8.3.6-7.el7ost.noarch && patch -d/ -p0 <<'EOF'
        --- /etc/puppet/modules/tripleo/manifests/profile/base/pacemaker.pp
        +++ /etc/puppet/modules/tripleo/manifests/profile/base/pacemaker.pp
        @@ -185,7 +185,7 @@
                   before             => Exec["exec-wait-for-${remote_short_node}"],
                   notify             => Exec["exec-wait-for-${remote_short_node}"],
                 }
        -        $check_command = "pcs status | grep -q -e \"${remote_short_node}.*Started\""
        +        $check_command = "pcs status | grep -q -e \"${remote_short_node}[[:blank:]].*Started\""
                 exec { "exec-wait-for-${remote_short_node}":
                   path      => '/usr/sbin:/usr/bin:/sbin:/bin',
                   command   => $check_command,
        EOF

outputs:
  OS::stack_id:
    value: {get_resource: userdata}
